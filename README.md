# Тестовое задание на вакансию Node.js разработчик от TAGES
Сортировка основана на алгоритме [external merge sort](https://en.wikipedia.org/wiki/External_sorting).
Согласно ему, имея файл размером 1 ТБ и RAM на 512 МБ, алгоритм будет по частям в размере 512 МБ читать этот файл, сортировать и записывать каждую часть в отдельные файлы.
После чтения файла будет создано 1 ТБ / 512 МБ = 2048 более мелких отсортированных файлов. Затем, используя алгоритм [K-way merge](https://en.wikipedia.org/wiki/K-way_merge_algorithm), файлы будут объединены в один большой отсортированный файл.

Основные настройки:
```
const BUFFER_CAPACITY = 1_000; // Вместимость внутреннего буффера потока в байтах
const MAX_MEM_USE = 10_000_000; // Размер в байтах создаваемых сортированных файлов
const FILE_NAME = "data.txt"; // Файл для сортировки
```

Выбрав Node.js я столкнулся с проблемой `JavaScript heap out of memory` из-за того, что Garbage Collector не успевал очищать память от мусора во время чтения и сортировки файлов.
Данную проблему я смог частично решить, уменьшив `BUFFER_CAPACITY` и `MAX_MEM_USE`.

Может появиться проблема `too many open files` из-за ограничений на количество открытых файловых дескрипторов у процесса. Решение можно найти [тут](https://sysadminium.ru/adm-serv-linux-limit-open-files-sysctl/).


